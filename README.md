The Fine-tuning BERT for LLM
# Performance Comparison Phishing Supervised vs LLM

## ğŸ“Œ Overview
This project investigates and compares two approaches for **detecting phishing web pages**:
1. **Traditional supervised learning models** using TF-IDF features + SVM/other classifiers.  
2. **Large Language Models (LLMs)** fine-tuned on phishing and legitimate website datasets.

The goal is to evaluate the trade-off between performance, scalability, and real-world applicability of supervised models vs. modern LLMs in phishing detection.

---

## ğŸš€ Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/PinturaW/performance-comparison-phishing-supervised-vs-llm.git
   cd performance-comparison-phishing-supervised-vs-llm
   ```

2. Create a virtual environment (recommended):

   ```bash
   python -m venv .venv
   source .venv/bin/activate   # macOS/Linux
   .venv\Scripts\activate      # Windows
   ```

3. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“Š Results & Performance

### LLM Performance Comparison by Training Epochs

| Training Epochs | Overall Accuracy | White (Legitimate) | Black (Phishing) | Macro F1-Score | Non-Phishing F1 | Phishing F1 |
|-----------------|------------------|-------------------|------------------|----------------|------------------|-------------|
| **1 Epoch**     | 81.0%           | 94.0% (47/50)    | 68.0% (34/50)   | 0.81          | 0.83            | 0.78        |
| **3 Epochs**    | **91.0%**       | 94.0% (47/50)    | 88.0% (44/50)   | **0.91**      | **0.91**        | **0.91**    |
| **5 Epochs**    | 92.0%           | 100.0% (50/50)   | 84.0% (42/50)   | 0.92          | 0.93            | 0.91        |

### Comprehensive Performance Metrics

#### 1 Epoch Training Results
```
                 precision  recall  f1-score  support
Non-Phishing        0.75    0.94     0.83       50
Phishing           0.92    0.68     0.78       50

accuracy                            0.81      100
macro avg          0.83    0.81     0.81      100
weighted avg       0.83    0.81     0.81      100
```

#### 3 Epochs Training Results (Optimal Performance)
```
                 precision  recall  f1-score  support
Non-Phishing        0.89    0.94     0.91       50
Phishing           0.94    0.88     0.91       50

accuracy                            0.91      100
macro avg          0.91    0.91     0.91      100
weighted avg       0.91    0.91     0.91      100
```

#### 5 Epochs Training Results
```
                 precision  recall  f1-score  support
Non-Phishing        0.86    1.00     0.93       50
Phishing           1.00    0.84     0.91       50

accuracy                            0.92      100
macro avg          0.93    0.92     0.92      100
weighted avg       0.93    0.92     0.92      100
```

### ğŸ¯ Production Recommendations

#### ğŸ† **Recommended Model: 3 Epochs**
**Why 3 epochs is optimal:**
- âœ… **Balanced Performance**: Equal F1-scores (0.91) across both classes
- âœ… **Stable Metrics**: Consistent precision/recall without overfitting
- âœ… **Business Impact**: Minimizes both false positives and false negatives
- âœ… **Resource Efficiency**: Good performance without excessive training time

#### ğŸ“Š **Comparative Analysis**
```
Model Comparison Summary:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Epochs    â”‚   Accuracy   â”‚  Phishing F1  â”‚    Trade-off    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚      1      â”‚     81%      â”‚     0.78      â”‚   Underfitting  â”‚
â”‚      3      â”‚     91%      â”‚     0.91      â”‚    âœ… Optimal   â”‚
â”‚      5      â”‚     92%      â”‚     0.91      â”‚  Overfitting?   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸš€ **Deployment Strategy**
1. **Primary Model**: 3-epoch BERT for real-time detection
2. **Confidence Thresholding**: Flag predictions below 85% confidence
3. **Human Review**: Manual verification for edge cases
4. **Continuous Learning**: Regular retraining with new phishing samples

#### ğŸ”„ **Model Monitoring**
- **Performance Tracking**: Monitor precision/recall drift over time
- **False Positive Analysis**: Weekly review of legitimate sites flagged as phishing
- **Adversarial Testing**: Monthly evaluation against new phishing techniques
- **A/B Testing**: Compare against traditional ML baseline

---

## ğŸ” Prediction Examples

### âœ… Legitimate Websites (White List)
- `th.edreams.com` â†’ **Legitimate** (97.68% confidence) âœ“
- `sanooklife.com` â†’ **Legitimate** (97.14% confidence) âœ“
- `microsoft.com` â†’ **Legitimate** (97.58% confidence) âœ“
- `icatcare.org` â†’ **Phishing** (97.30% confidence) âš ï¸ *False Positive*

### ğŸš¨ Phishing Websites (Black List)
- `gold1-1.github` â†’ **Phishing** (97.59% confidence) âœ“
- `gratulejemy2750` â†’ **Phishing** (85.58% confidence) âœ“
- `flarenetwork` â†’ **Phishing** (94.16% confidence) âœ“
- `bxterioronlin` â†’ **Legitimate** (96.68% confidence) âŒ *False Negative*

---

## ğŸ“ˆ Key Insights

### ğŸŸ¢ Strengths
- **High Overall Accuracy**: 91% balanced accuracy across both categories
- **Excellent Precision**: Very reliable on legitimate website detection
- **Fast Inference**: 13.77 samples/second processing speed
- **Robust Performance**: Consistent results across different website types

### ğŸ”´ Areas for Improvement
- **False Negatives**: Some sophisticated phishing sites bypass detection
- **Domain Generalization**: Performance may vary on novel phishing techniques
- **Resource Requirements**: LLM approach requires more computational resources

### ğŸ¯ Recommendations
- **For Production**: 3-epoch model provides optimal accuracy-efficiency balance
- **Training Data**: Include more adversarial examples to reduce false negatives
- **Ensemble Approach**: Combine LLM with traditional features for enhanced performance

---

## ğŸ‘¥ Contributions

* **Supervised Learning Pipeline** â€“ handled by project collaborators
* **LLM Pipeline** â€“ developed and fine-tuned by **Wichuon Charoensombat (PinturaW)**

---

## ğŸ“¬ Contact

Developed by **Wichuon Charoensombat** (PinturaW)
ğŸ“§ Reach me on [LinkedIn](https://www.linkedin.com/in/wichuon-charoensombat) or GitHub

---
